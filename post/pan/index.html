<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>PAN++ | 蜗牛OCR</title>
<link rel="shortcut icon" href="https://fireae.github.io/favicon.ico?v=1660039048091">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://fireae.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="PAN++ | 蜗牛OCR - Atom Feed" href="https://fireae.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="PAN++：精确高效的任意形状文本端到端检测与识别 [TPAMI 2021]
论文地址
代码地址
本文简要介绍了TPAMI2021录用论文“PAN++: Towards Efficient and Accurate End-to-End S..." />
    <meta name="keywords" content="文本行检测,text detect,text detection,scene text recognition e2e" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://fireae.github.io">
  <img class="avatar" src="https://fireae.github.io/images/avatar.png?v=1660039048091" alt="">
  </a>
  <h1 class="site-title">
    蜗牛OCR
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              PAN++
            </h2>
            <div class="post-info">
              <span>
                2022-07-21
              </span>
              <span>
                6 min read
              </span>
              
                <a href="https://fireae.github.io/tag/4j-zalQP4/" class="post-tag">
                  # 文本行检测
                </a>
              
                <a href="https://fireae.github.io/tag/jmPfYBroRj/" class="post-tag">
                  # text detect
                </a>
              
                <a href="https://fireae.github.io/tag/vAxXdZjIkN/" class="post-tag">
                  # text detection
                </a>
              
                <a href="https://fireae.github.io/tag/lWA4Gd-_zx/" class="post-tag">
                  # scene text recognition e2e
                </a>
              
            </div>
            
              <img class="post-feature-image" src="https://fireae.github.io/post-images/pan.jpg" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content" v-pre>
                <p>PAN++：精确高效的任意形状文本端到端检测与识别 [TPAMI 2021]<br>
<a href="https://arxiv.org/pdf/2105.00405.pdf">论文地址</a><br>
<a href="https://github.com/whai362/pan_pp.pytorch">代码地址</a></p>
<p>本文简要介绍了TPAMI2021录用论文“PAN++: Towards Efficient and Accurate End-to-End Spotting of Arbitrarily-Shaped Text”。该论文展示了一种基于文本内核（即中心区域）的任意形状文本的表示方法，可以较好地区分相邻文本，且对实时的应用场景非常友好。在此基础上，作者建立了一个高效的端到端框架PAN++，可以有效地检测和识别自然场景中任意形状的文本，并且同时做到了高推理速度和高精度。</p>
<!-- more -->
<p><img src="https://fireae.github.io/post-images/1658399975582.jpg" alt="" loading="lazy"><br>
其中，(a) 四边形表示无法定位弯曲的文本行。(b) 像素级表示不能分隔相邻的文本行。(c) 虽然边界框像素(bbox-pixel)表示可以容纳弯曲和相邻的文本行，但它需要两阶段预测，但是计算较为昂贵。(d) 我们的Kernel表示是单阶段的，对弯曲和相邻的文本行是鲁棒的。</p>
<h2 id="1-背景研究">1. 背景研究</h2>
<p>自然场景文本检测与识别是文本检索、自动化办公、可视化问答等众多应用的一项基本任务。近些年，场景文本检测与识别取得了瞩目的进展，但这些方法仍存在三个主要局限性，限制了其在实际应用中的部署。首先，大多数现有的工作将文本检测和识别作为独立的任务进行处理，很少有方法探讨这两项任务之间的互补性。第二，大多数现有的端到端文本检测与识别方法通常针对水平或定向文本设计，然而除了直线型文本外，不规则形状的文本在自然场景也极为常见。最后，现有方法的效率仍不能满足实际应用需求。最近的一些方法[1-2]致力于提高端到端任意形状文本检测与识别的精度，但是由于模型参数过多或算法流程复杂，导致其推理速度较低。因此，如何为任意形状的文本设计一个高效且精确的端到端检测与识别框架仍然是一个亟待解决的问题。</p>
<h2 id="2-原理概述">2. 原理概述</h2>
<p><img src="https://fireae.github.io/post-images/1658400097100.jpg" alt="" loading="lazy"><br>
PAN++的整体架构如图2所示。为了提高推理速度，作者主要采用了轻量级的ResNet18[3]作为骨干网络。但是，轻量级网络具有感受野小和表征能力弱的缺点，针对这一问题，本文提出使用堆叠的特征金字塔增强模块（FPEM）来增强提取到的特征。</p>
<p><img src="https://fireae.github.io/post-images/1658400125148.jpg" alt="" loading="lazy"><br>
如图3所示，FPEM是基于可分离卷积构建的U形模块，可以以较小的计算开销增强骨干网络提取的多尺度特征。另外，FPEM是可堆叠的，随着堆叠层数的增加，网络的感受野也将增大。</p>
<p><img src="https://fireae.github.io/post-images/1658400151217.png" alt="" loading="lazy"><br>
对于文本检测任务，本文提出了一个仅包含两层卷积的轻量级检测头，如图4所示。该检测头同时预测生成文本区域、文本内核以及实例向量，再通过PA算法融合得到最终的检测结果。</p>
<p><img src="https://fireae.github.io/post-images/1658400175842.jpg" alt="" loading="lazy"><br>
PA的设计借用了聚类的思想，如图5所示。如果把不同的文本看作不同的簇，则文本内核就是簇的中心，文本区域内的像素就是待聚类的样本。</p>
<p><img src="https://fireae.github.io/post-images/1658400190109.jpg" alt="" loading="lazy"><br>
对于文本识别任务，作者提出了一个不规则文字特征提取器Masked RoI和一个基于注意力机制的轻量级识别头。Masked RoI是一个用于为任意形状的文本提取固定大小的特征块的RoI提取器，而轻量级识别头仅包含两层LSTM和两层多头注意力，如图6所示。</p>
<p>对于检测部分，本文使用的损失函数为：<br>
<img src="https://fireae.github.io/post-images/1658400276436.png" alt="" loading="lazy"></p>
<p>对于识别部分，本文使用的损失函数为：<br>
<img src="https://fireae.github.io/post-images/1658400289714.png" alt="" loading="lazy"></p>
<p>得益于上述设计，PAN++在保持精度具有竞争力的同时，实现了较高的推理速度。PAN++与其它方法的性能对比如图7所示。<br>
<img src="https://fireae.github.io/post-images/1658400315385.jpg" alt="" loading="lazy"></p>
<h2 id="3-实验结果与分析">3. 实验结果与分析</h2>
<p>如表1和表2所示，在没有使用额外数据集预训练的情况下，PAN ++在Total-Text[4]和CTW1500[5]上取得了具有竞争力的结果。在使用SynthText[6]数据集预训练后，PAN++的精度进一步提高并取得了SOTA的效果。在短边为320像素的输入下，PAN++实现了超过84FPS的推理速度，超过了其它具有相似精度的方法。</p>
<p>表2展示了PAN++在Total-Text数据集上的端到端文本识别结果。这些结果表明，PAN++在文本识别任务中取得了SOTA的性能，并且在推理速度上显著优于现有方法。<br>
<img src="https://fireae.github.io/post-images/1658400368641.jpg" alt="" loading="lazy"></p>
<center>表1</center>
<figure data-type="image" tabindex="1"><img src="https://fireae.github.io/post-images/1658400387033.jpg" alt="" loading="lazy"></figure>
<center>表2</center>
<h2 id="4-总结">4. 总结</h2>
<p>在这篇文章中，作者大大扩展了文本定位的内核表示，还深入讨论了该方法在实时任意形状文本识别中的可行性。特别是，为了进一步加强这种表示，作者开发了一个端到端任意形状的文本定位的有效框架，通过精心设计一系列轻量级模块，设法加快了文本定位过程的所有部分，包括：</p>
<ul>
<li>具有堆叠fpm的特征增强网络。</li>
<li>具有PA的检测头。</li>
<li>具有掩蔽RoI的识别头。</li>
</ul>
<p>在本文中，作者提出了对任意形状文本友好的内核表示，并在此基础上开发了一个端到端的文本检测与识别框架PAN++，通过设计一系列轻量级模块，实现了高效且精确的任意形状文本检测与识别。与其它现有方法相比，PAN++在精度和推理速度上都具有显著优势。</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#1-%E8%83%8C%E6%99%AF%E7%A0%94%E7%A9%B6">1. 背景研究</a></li>
<li><a href="#2-%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0">2. 原理概述</a></li>
<li><a href="#3-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E4%B8%8E%E5%88%86%E6%9E%90">3. 实验结果与分析</a></li>
<li><a href="#4-%E6%80%BB%E7%BB%93">4. 总结</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://fireae.github.io/post/hello-gridea/">
              <h3 class="post-title">
                Hello Gridea
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://fireae.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
